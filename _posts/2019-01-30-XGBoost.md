---
title: "XGBoost"
date: 2019-01-30
classes: wide
use_math: true
tags: python keras tensorflow reinforcement_learning machine_learning  GAN XGboost
category: reinforcement learning
---


[using XGBoost](https://www.datacamp.com/community/tutorials/xgboost-in-python#what)

[XGBoost example](https://www.kdnuggets.com/2017/03/simple-xgboost-tutorial-iris-dataset.html)

[Get Started with XGBoost](https://xgboost.readthedocs.io/en/latest/get_started.html)

[Example XGboost Grid Search in Python](http://hack-r.com/example-xgboost-grid-search-in-python/)


- XGBoost (Extreme Gradient Boosting) belongs to a family of boosting algorithms and uses the gradient boosting (GBM) framework at its core. It is an optimized distributed gradient boosting library. 

![](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1528107577/output_1_0_ilvuyr.png)

- Box 4: This is a weighted combination of the weak classifiers (Box 1,2 and 3). As you can see, it does a good job at classifying all the points correctly.

### XGBoost's hyperparameters  

-  learning_rate: step size shrinkage used to prevent overfitting. Range is [0,1]
-  max_depth: determines how deeply each tree is allowed to grow during any boosting round.
-  subsample: percentage of samples used per tree. Low value can lead to underfitting.
-  colsample_bytree: percentage of features used per tree. High value can lead to overfitting.
-  n_estimators: number of trees you want to build.
-  objective: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, 
-  binary:logistic for classification problems with probability.


- gamma: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.
- alpha: L1 regularization on leaf weights. A large value leads to more regularization.
- lambda: L2 regularization on leaf weights and is smoother than L1 regularization.







